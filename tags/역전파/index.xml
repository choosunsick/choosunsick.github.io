<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>역전파 on Sunsick&#39;s blog</title>
    <link>https://choosunsick.github.io/tags/%EC%97%AD%EC%A0%84%ED%8C%8C/</link>
    <description>Recent content in 역전파 on Sunsick&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko</language>
    <lastBuildDate>Mon, 30 Mar 2020 22:07:37 +0900</lastBuildDate>
    
	<atom:link href="https://choosunsick.github.io/tags/%EC%97%AD%EC%A0%84%ED%8C%8C/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>오차역전파법을 적용한 2층 신경망 구현하기</title>
      <link>https://choosunsick.github.io/post/neural_network_backward_4/</link>
      <pubDate>Mon, 30 Mar 2020 22:07:37 +0900</pubDate>
      
      <guid>https://choosunsick.github.io/post/neural_network_backward_4/</guid>
      <description>오차역전파법을 적용한 2층 신경망 구현하기 이제 오차역전파법이 적용된 2층 신경망을 구현해보겠습니다. 역전파가 적용된 신경망 모델 역시 기존 순전파에서 진행한</description>
    </item>
    
    <item>
      <title>다양한 역전파 계층 구현하기</title>
      <link>https://choosunsick.github.io/post/neural_network_backward_3/</link>
      <pubDate>Mon, 30 Mar 2020 22:07:35 +0900</pubDate>
      
      <guid>https://choosunsick.github.io/post/neural_network_backward_3/</guid>
      <description>각 계층 구현하기 이번에는 신경망 모델에서 역전파를 하기 위해 필요한 함수들 예를 들어 softmax()와 loss(), sigmoid(), ReLU() 기존 순전파 계산model.forward(</description>
    </item>
    
    <item>
      <title>역전파와 간단한 계산문제</title>
      <link>https://choosunsick.github.io/post/neural_network_backward_2/</link>
      <pubDate>Mon, 30 Mar 2020 22:07:33 +0900</pubDate>
      
      <guid>https://choosunsick.github.io/post/neural_network_backward_2/</guid>
      <description>역전파 계산그래프의 역전파는 부분적인 계산을 계속 출력하여 최종 계산을 이끌어내듯이 연쇄법칙과 같은 원리를 사용합니다. 즉 복잡한 미분을 작은 계산들의 곱으로 표</description>
    </item>
    
    <item>
      <title>계산 그래프와 연쇄법칙</title>
      <link>https://choosunsick.github.io/post/neural_network_backward_1/</link>
      <pubDate>Mon, 30 Mar 2020 22:07:30 +0900</pubDate>
      
      <guid>https://choosunsick.github.io/post/neural_network_backward_1/</guid>
      <description>앞선 글에서는 손실 함수의 기울기를 계산해 각 가중치와 편향에 대해 수치미분으로 그 값을 갱신하였습니다. 그러나 이 방식은 너무 오래걸린다는 단점이 있습니다. 이번</description>
    </item>
    
  </channel>
</rss>